{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "8D35vSs2M-Qw",
    "outputId": "dd331241-d07a-4ad3-cbf6-bc983ce3f902"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_w0YZt09M7-n"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/EVA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "nSMAyBhzHaZm",
    "outputId": "1e21b27c-c582-45e6-bbd4-7a2464b3d013"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from resnet import ResNet\n",
    "from cutout import get_random_eraser\n",
    "from lr_finder import LR_Finder \n",
    "from clr_callback import CyclicLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1hCCNCPkizKd"
   },
   "source": [
    "- Your model must look like Conv->B1->B2->B3->B4 and not individually called Convs. \n",
    "If not already using, then:\n",
    "- Use Batch Size 128\n",
    "- Use Normalization values of: (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "- Random Crop of 32 with padding of 4px\n",
    "Horizontal Flip (0.5)\n",
    "- Optimizer: SGD, Weight-Decay: 5e-4\n",
    "- NOT-OneCycleLR\n",
    "- Save model (to drive) after every 50 epochs or best model till now\n",
    "- Describe your blocks, and the stride strategy you have picked\n",
    "- Train for 300 Epochs\n",
    "- Assignment Target Accuracy is 90%, so exit gracefully if you reach 90% (you can target more, it can go till ~93%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6OwxXNiaO6dm"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
    "MOMENTUM = 0.9 #@param {type:\"number\"}\n",
    "LEARNING_RATE = 0.4 #@param {type:\"number\"}\n",
    "WEIGHT_DECAY = 5e-4 #@param {type:\"number\"}\n",
    "EPOCHS = 24 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zELf8wAiPKLP",
    "outputId": "bff3dc8c-6a30-4498-b113-193722028343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calc mean: [125.30691805 122.95039414 113.86538318]\n",
      "Calc std: [62.99321928 62.08870764 66.70489964]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "len_train, len_test = len(x_train), len(x_test)\n",
    "y_train = y_train.astype('int64').reshape(len_train)\n",
    "y_test = y_test.astype('int64').reshape(len_test)\n",
    "\n",
    "train_mean = np.mean(x_train, axis=(0,1,2))\n",
    "train_std = np.std(x_train, axis=(0,1,2))\n",
    "\n",
    "given_mean, given_std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "print(\"Calc mean:\", train_mean)\n",
    "print(\"Calc std:\", train_std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RtEMSE86O8lV"
   },
   "outputs": [],
   "source": [
    "normalize = lambda x: ((x - given_mean) / given_std).astype('float32') # todo: check here\n",
    "pad4 = lambda x: np.pad(x, [(0, 0), (4, 4), (4, 4), (0, 0)], mode='reflect')\n",
    "\n",
    "x_train = normalize(pad4(x_train))\n",
    "x_test = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1qjRG8JSG0r"
   },
   "outputs": [],
   "source": [
    "norm_x_train_mean = np.mean(x_train, axis=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "uXgcbUUXMycn",
    "outputId": "e7a816fc-76a2-4fbe-c0bb-1ea42b8eca6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n",
      "reshaping via a convolution...\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(input_shape=(32,32,3), classes=10, block='basic', residual_unit='v2',\n",
    "                  repetitions=[2,2,2,2], initial_filters=64, activation='softmax', include_top=True,\n",
    "                  input_tensor=None, dropout=None, transition_dilation_rate=(1, 1),\n",
    "                  initial_strides=(1, 1), initial_kernel_size=(3, 3), initial_pooling=None,\n",
    "                  final_pooling='avg', top='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nk9NKddBO0XX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1EFXp1p_Ku_0"
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr_func, momentum=MOMENTUM, use_nesterov=True, decay=WEIGHT_DECAY)\n",
    "\n",
    "checkpoint = ModelCheckpoint(file=\"best_model.h5\",\n",
    "                             save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJW4IFrYQBRH"
   },
   "outputs": [],
   "source": [
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "\n",
    "def crop_generator(batches, crop_length):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdA1Qd8mLPr5"
   },
   "outputs": [],
   "source": [
    "cutout = lambda x: \n",
    "random_crop = lambda x, y: (tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3])), y)\n",
    "\n",
    "train_datagen = ImageDataGenerator(......)\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
    "                                                  target_size=(256,256),\n",
    "                                                  ......)\n",
    "train_crops = crop_generator(train_batches, 224)\n",
    "......\n",
    "net_final.fit_generator(train_crops, ......)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHUF71opSD5C"
   },
   "outputs": [],
   "source": [
    "sgd = SGD(l)\n",
    "\n",
    "batches_per_epoch = len_train//BATCH_SIZE + 1\n",
    "\n",
    "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, EPOCHS], [0, LEARNING_RATE, 0])[0]\n",
    "lr_func = lambda: lr_schedule(global_step/batches_per_epoch)/BATCH_SIZE\n",
    "opt = tf.train.MomentumOptimizer(lr_func, momentum=MOMENTUM, use_nesterov=True)\n",
    "data_aug = lambda x, y: (tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3])), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXpThjwvJlfp"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(pixel_value=norm_x_train_mean), \n",
    "                             horizontal_flip=True)\n",
    "datagen.fit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 13 Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
