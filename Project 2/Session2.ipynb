{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# **Not an ideal network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "outputId": "a48188fe-9d77-482c-c711-3c7ef71c3336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# usual incantations  \n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras provide mnist dataset with its package\n",
        "# here we are loading the dataset into memory\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "22cef461-d965-4a79-8e4c-43b87fb81ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "'''\n",
        "we are printing the image. By eye balling the image, we get know approximately \n",
        "how many convolutional layers we need to add to learn edges and gradients in the \n",
        "starting layers and then add max pooling layer. Hhre, the object (number 2) \n",
        "looks to be of 20x20 size and receptive field of size 7x7 seems to be good to \n",
        "capture the edges and gradients.\n",
        "'''\n",
        "plt.imshow(X_train[5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5e29ba8ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADuBJREFUeJzt3X2wVPV9x/HPl8sVlISGJ2+uQEKI\nWMvDCO0VWkMTrTFjHCsmdjRM0yHTTEinkDYOk9SHmcRMZjq202ixzUOvDRFNgnZ8iDRxYixjxmS0\nDheiIEEeQlChPKg4giJw7+XbP+7BudF7frvsnt2z+H2/Zu7c3fPds+fLwoez5/x2z8/cXQDiGVZ2\nAwDKQfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwQ1vJkbO81G+EiNauYmgVCO6HUd86NWzWPr\nCr+ZXSppuaQ2Sf/p7jenHj9SozTPLq5nkwASnvQ1VT+25rf9ZtYm6ZuSPi5puqSFZja91ucD0Fz1\nHPPPlbTd3Xe4+zFJd0taUExbABqtnvBPlPTCoPu7smW/w8wWm1mPmfX06mgdmwNQpIaf7Xf3bnfv\ncveudo1o9OYAVKme8O+WNHnQ/UnZMgCngHrCv1bSNDP7gJmdJulTklYX0xaARqt5qM/d+8xsqaSH\nNTDUt8LdNxXWGYCGqmuc390fkvRQQb0AaCI+3gsERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo\nwg8ERfiBoAg/EBThB4Ii/EBQdc3Sa2Y7JR2S1C+pz927imgKp462cWOTdfu90bm15686K7nukfGe\nrJ/9taeT9eOHDyfr0dUV/sxF7v5SAc8DoIl42w8EVW/4XdLPzGydmS0uoiEAzVHv2/757r7bzM6U\n9IiZPevujw1+QPafwmJJGqkz6twcgKLUted3993Z7/2SHpA0d4jHdLt7l7t3tWtEPZsDUKCaw29m\no8zs3SduS/qYpGeKagxAY9Xztr9D0gNmduJ5fujuPy2kKwANV3P43X2HpPMK7AUlGDbz3GR92/Wn\nJ+t/PevxZH3ZuIdPuqdq/UHH3yTr0z6zrmHbfidgqA8IivADQRF+ICjCDwRF+IGgCD8QVBHf6kPJ\n7PxZubXt17Yl1/35/H9P1ie0pT+VOazC/uMnh8fk1nYcPTO57pIxW5L1uz58e7L+9fMX5dZ87cbk\nuhGw5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnbwFtEyYk61uXT0zW//uCb+XWpra3V9h6fVdX\n+t7Bycn6j66an1s7PiLd25Ifp8f5u0b0J+tvdOR/HXlkcs0Y2PMDQRF+ICjCDwRF+IGgCD8QFOEH\ngiL8QFCM87eA3Z+elqxv+sjyCs9QaSy/dt+vNI5/5QXJev+Wrbk1mzOjpp5QDPb8QFCEHwiK8ANB\nEX4gKMIPBEX4gaAIPxBUxXF+M1sh6XJJ+919ZrZsrKR7JE2RtFPS1e7+SuPafGebeMXOhj33va+9\nN1m/ZevFyXrHlz1Z79+y7aR7OuGVWaNrXhf1q2bPf4ekS9+y7DpJa9x9mqQ12X0Ap5CK4Xf3xyQd\neMviBZJWZrdXSrqy4L4ANFitx/wd7r4nu71XUkdB/QBokrpP+Lm7S8o9MDSzxWbWY2Y9vTpa7+YA\nFKTW8O8zs05Jyn7vz3ugu3e7e5e7d7XXebFIAMWpNfyrJZ2YAnWRpAeLaQdAs1QMv5mtkvSEpN83\ns11m9llJN0u6xMy2Sfpodh/AKaTiOL+7L8wppQeIUb3PpQ+Hpi/5QrI++ZH869eP2rQ3ue745/K/\nby9J6Svj1+dwhzXw2VEJn/ADgiL8QFCEHwiK8ANBEX4gKMIPBMWlu1tA//bfJutnX5uup/TVvGbj\n9Z5/qOwWQmPPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc4f3PNfSU+x3XdG+tLdqvSt3MTqn5z2\nRIWV05buujBZP/2n63NrFf5UIbDnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOc/BbSNTk9lfWTu\ntNxa+/X7kutuOPffaurpzee3tmS912u/+Pejb5yRrO9a/L5k3fs217ztCNjzA0ERfiAowg8ERfiB\noAg/EBThB4Ii/EBQFcf5zWyFpMsl7Xf3mdmymyR9TtKL2cNucPeHGtXkqc5GpKfgPvaRWcn6td+6\nK1m/6PQ1ubV9/UeT6z76xphk/StbFyTrq2bckayfNTz9Z08ZOaw3Wd9x9XuS9albRubWjh85UlNP\n7yTV7PnvkHTpEMtvdffZ2Q/BB04xFcPv7o9JOtCEXgA0UT3H/EvNbIOZrTCz9HtHAC2n1vB/W9IH\nJc2WtEfSN/IeaGaLzazHzHp6lT7+BNA8NYXf3fe5e7+7H5d0u6S5icd2u3uXu3e1q/aTPwCKVVP4\nzaxz0N1PSHqmmHYANEs1Q32rJF0oabyZ7ZL0VUkXmtlsDVwBeaekzzewRwANYO7Nu4L5aBvr8+zi\npm2vWYaNzB9PlqSXr5mTrP/iH2+ra/szVn0htzbp0fT36Uf8ZG2yPrzzvcn6hx7+bbK+bFx5bwr/\n5Ot/l1vruPPp5LrHDx8uup2meNLX6KAfqDSbgiQ+4QeERfiBoAg/EBThB4Ii/EBQhB8IiqG+KqW+\nlrvl1vOS6z674Jt1bXvBliuT9WEL87/62r9vf3Ld4ZMnJevnrX4+Wf/amb9K1l89nv/V2Xn3LUuu\n23luuvc1s+5J1lOu2X55sv7SbVOS9ZEvp79uXEnbz/OnD68HQ30AKiL8QFCEHwiK8ANBEX4gKMIP\nBEX4gaCYojtjw9MvxZZ/zR/Lf/aK9Dj+rr705cuu+I8vJ+tTVvwmWe9LjOX3fvSPkuvO/Kf0OP1X\nz1yXrH/v4PuT9btu/PPc2tn3/29y3bbx45L1Cy/J/yqzJL1+zau5tQfm3J5cd9Jt9V116sevp3vv\nPmdqXc9fBPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU3+fP7Lr+gmR9/dLlubX/qzCOf9XNX0rW\nO3+Uvvz1gYumJOv+6Zdya/fOvCO57oS29Hj2jLvTY+nndOdvW5L6t2xP1suy/2/Tf98df/FcfRtY\nlp4+3H+1qb7nz8H3+QFURPiBoAg/EBThB4Ii/EBQhB8IivADQVUc5zezyZLulNQhySV1u/tyMxsr\n6R5JUyTtlHS1u7+Seq5WHue/ccdTyfq8EfnXaT/Qnx7n/84r85L1iaclXzYtGl3nmHPCjB/mT2Mt\nSWdfn57C2/v6imwHdSp6nL9P0jJ3ny7pjyUtMbPpkq6TtMbdp0lak90HcIqoGH533+Pu67PbhyRt\nljRR0gJJK7OHrZSUnlYGQEs5qWN+M5siaY6kJyV1uPuerLRXA4cFAE4RVYffzN4l6T5JX3T3g4Nr\nPnDiYMiTB2a22Mx6zKynV+ljYwDNU1X4zaxdA8H/gbvfny3eZ2adWb1T0pBXkXT3bnfvcveudtV3\nUUQAxakYfjMzSd+VtNndbxlUWi1pUXZ7kaQHi28PQKNUM9Q3X9IvJG2UdDxbfIMGjvv/S9L7JD2n\ngaG+A6nnauWhvj/dkD+VtCR9adzGJnXydpc/+8lk/fkn8qfZnnpv/uWrJck3pb9y673HknW0lpMZ\n6qt43X53/6WkvCdrzSQDqIhP+AFBEX4gKMIPBEX4gaAIPxAU4QeCYoruzOMXnZWsz/vLP8utvXpe\neix8+Ivtyfo539mdXn9v/hTckjTlyAu5teO5FUTHnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKc\nP9P/cvJSBOq47fH8Wp3b5uLXKAN7fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwiqYvjNbLKZPWpmvzazTWb299nym8xst5k9lf1c1vh2ARSlmot59Ela\n5u7rzezdktaZ2SNZ7VZ3/5fGtQegUSqG3933SNqT3T5kZpslTWx0YwAa66SO+c1siqQ5kp7MFi01\nsw1mtsLMxuSss9jMesysp1dH62oWQHGqDr+ZvUvSfZK+6O4HJX1b0gclzdbAO4NvDLWeu3e7e5e7\nd7VrRAEtAyhCVeE3s3YNBP8H7n6/JLn7Pnfvd/fjkm6XNLdxbQIoWjVn+03SdyVtdvdbBi3vHPSw\nT0h6pvj2ADRKNWf7PyTpryRtNLOnsmU3SFpoZrMluaSdkj7fkA4BNEQ1Z/t/KcmGKD1UfDsAmoVP\n+AFBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Iyd2/exsxe\nlPTcoEXjJb3UtAZOTqv21qp9SfRWqyJ7e7+7T6jmgU0N/9s2btbj7l2lNZDQqr21al8SvdWqrN54\n2w8ERfiBoMoOf3fJ209p1d5atS+J3mpVSm+lHvMDKE/Ze34AJSkl/GZ2qZltMbPtZnZdGT3kMbOd\nZrYxm3m4p+ReVpjZfjN7ZtCysWb2iJlty34POU1aSb21xMzNiZmlS33tWm3G66a/7TezNklbJV0i\naZektZIWuvuvm9pIDjPbKanL3UsfEzazD0t6TdKd7j4zW/bPkg64+83Zf5xj3P0fWqS3myS9VvbM\nzdmEMp2DZ5aWdKWkz6jE1y7R19Uq4XUrY88/V9J2d9/h7sck3S1pQQl9tDx3f0zSgbcsXiBpZXZ7\npQb+8TRdTm8twd33uPv67PYhSSdmli71tUv0VYoywj9R0guD7u9Sa0357ZJ+ZmbrzGxx2c0MoSOb\nNl2S9krqKLOZIVScubmZ3jKzdMu8drXMeF00Tvi93Xx3/0NJH5e0JHt725J84JitlYZrqpq5uVmG\nmFn6TWW+drXOeF20MsK/W9LkQfcnZctagrvvzn7vl/SAWm/24X0nJknNfu8vuZ83tdLMzUPNLK0W\neO1aacbrMsK/VtI0M/uAmZ0m6VOSVpfQx9uY2ajsRIzMbJSkj6n1Zh9eLWlRdnuRpAdL7OV3tMrM\nzXkzS6vk167lZrx296b/SLpMA2f8fyPpxjJ6yOlrqqSns59NZfcmaZUG3gb2auDcyGcljZO0RtI2\nSf8jaWwL9XaXpI2SNmggaJ0l9TZfA2/pN0h6Kvu5rOzXLtFXKa8bn/ADguKEHxAU4QeCIvxAUIQf\nCIrwA0ERfiAowg8ERfiBoP4ffm+Zwo6qf/gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Shape of image in the dataset doesn't has third channel as it's a black and \n",
        "white image. Therefore, we add third channel as 1 here as the input dimension to\n",
        "the conv layers must have 3 dimensions.\n",
        "'''\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Normalising the image to 0 to 1 range which helps in faster convergence.  \n",
        "'''\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "91574e7b-cfe5-42c6-b9ed-66fc133d5614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# printing first 10 elements of y vector\n",
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "0e8d1616-d2bd-439c-83d4-a9a3b4df8cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# after using one hot encoding, printing the elements of y vector \n",
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "591d61ff-eeb0-4eb1-8252-a9319542680f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        }
      },
      "source": [
        "#In this cell, we define our CNN model to classify the digits in the images. \n",
        "\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) # input shape : 28x28x1, RF of layer1: 3\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) # input shape: 26x26x32, RF of layer2: 5\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu')) # input shape: 24x24x64, RF of layer3: 7\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # input shape: 22x22x128, RF of layer4: 14\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu')) # input shape: 11x11x128, RF of layer5: 16\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu')) # input shape: 9x9x256, RF of layer6: 18\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu')) # input shape: 7x7x512, RF of layer6: 20\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu')) # input shape: 5x5x1024, RF of layer6: 22\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # input shape: 3x3x2048, RF of layer6: 24\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 11:49:59.980654 140043660154752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "W0727 11:50:00.001131 140043660154752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 11:50:00.003778 140043660154752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "W0727 11:50:00.040166 140043660154752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "outputId": "14bc7c83-a069-45a8-e7b7-c77179a669cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "'''\n",
        "Here we define loss function for the model using which gradient \n",
        "descent optimizer (Adam) and which metric (accuracy) to maximise\n",
        "'''\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 11:50:24.702641 140043660154752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 11:50:24.730851 140043660154752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "0a2d798e-7a6b-44a0-d428-8e462f79d3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "# we train the model for 10 epochs here \n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "W0727 11:50:25.480884 140043660154752 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0727 11:50:25.560332 140043660154752 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 1.9367 - acc: 0.2730\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 1.8980 - acc: 0.2819\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 1.8905 - acc: 0.2836\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 1.8869 - acc: 0.2847\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 1.8823 - acc: 0.2852\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 1.8902 - acc: 0.2829\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.2405 - acc: 0.1299\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 115s 2ms/step - loss: 2.3026 - acc: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e517a0978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluating the moddel score of the test data\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15be80f9-db5a-4134-ff4a-00fa3d0a272d"
      },
      "source": [
        "# printing the score of the model\n",
        "print(score)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3025851249694824, 0.098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the predictions of the model on test data\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "21113b65-80ff-4f71-d4a9-b0cf0885903d"
      },
      "source": [
        "# printing the first 10 predictions and comparing against the actuals\n",
        "# Looking at the output, the model doesn't seem to be working at all\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4RMwqDVKHYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "What's wrong with this model? The number of kernels from 3rd conv layer onwards \n",
        "doesn't seem to be justified. MNIST images are relaitvely very simple. They have\n",
        "limited number of edges, curves and gradients to learn and since the images are\n",
        "in black and white format that further reduces the complexity of images. This \n",
        "means that we don't need that many number of  kernels, especially the \n",
        "number of kernels we see after 3rd conv layer. We could have instead used 1D\n",
        "convolution to reduce the number of channels in the input  after third conv layer\n",
        "and then, again increase the number of kernels till 128 or so. This would have brought \n",
        "the number of parameters to learn significantly down. \n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
